{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas (Python programming language for data manipulation and analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "Series are going to be a new datatype that are similar to numpy arrays, as they are one type, but take on a completely different approach to manipulating data.\n",
    " - Series have an index attribute, which is the row location of the data\n",
    " - Manipulating a Series won't affect the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -2\n",
      "1    1\n",
      "2    0\n",
      "3   -1\n",
      "4    2\n",
      "dtype: int64\n",
      "\n",
      "**************Index/Values:\n",
      "RangeIndex(start=0, stop=5, step=1)\n",
      "[-2  1  0 -1  2]\n",
      "\n",
      "**************Defining Indexes:\n",
      "a   -2\n",
      "b    1\n",
      "c    0\n",
      "d   -1\n",
      "e    2\n",
      "dtype: int64\n",
      "\n",
      "**************Numpy operations maintain the indexes:\n",
      "a   -6\n",
      "b    3\n",
      "c    0\n",
      "d   -3\n",
      "e    6\n",
      "dtype: int64\n",
      "a   -2\n",
      "d   -1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # same as numpy, you'll usually see this as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Working with Series\n",
    "\n",
    "s1 = Series([-2, 1, 0, -1, 2])\n",
    "print(s1) # elements on the left are the index, also notice it incorporates a dtype (Numpy)\n",
    "\n",
    "# Similar to a dictionary it has index, values\n",
    "print(\"\\n**************Index/Values:\")\n",
    "print(s1.index)\n",
    "print(s1.values)\n",
    "\n",
    "print(\"\\n**************Defining Indexes:\")\n",
    "s2 = Series([-2, 1, 0, -1, 2], index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s2)\n",
    "\n",
    "\n",
    "print(\"\\n**************Numpy operations maintain the indexes:\")\n",
    "print(s2*3)\n",
    "print(s2[s2 < 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We can actually define these indexes to make them non-numeric\n",
    " - indexes control a lot of the logic on how Series interact with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    23.0\n",
      "f     9.0\n",
      "b   -21.0\n",
      "e     3.0\n",
      "dtype: float64\n",
      "\n",
      "*************Checking for existence:\n",
      "True\n",
      "False\n",
      "True\n",
      "\n",
      "**************Passing in dict and index:\n",
      "a    23.0\n",
      "f     9.0\n",
      "b   -21.0\n",
      "d     NaN\n",
      "dtype: float64\n",
      "\n",
      "**************Adding Series:\n",
      "a    46.0\n",
      "b   -42.0\n",
      "d     NaN\n",
      "e     NaN\n",
      "f    18.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Actually Series are almost Numpy Dicts\n",
    "\n",
    "d = {'a': 23, 'f':9, 'b': -21, 'e': 3.0}\n",
    "s1 = Series(d)\n",
    "print(s1) # Note it actually sorts the keys\n",
    "\n",
    "print(\"\\n*************Checking for existence:\")\n",
    "print('a' in s1) # Only works for index\n",
    "print(23 in s1)\n",
    "print(23 in s1.values)\n",
    "\n",
    "print(\"\\n**************Passing in dict and index:\")\n",
    "d = {'a': 23, 'f':9, 'b': -21, 'e': 3.0}\n",
    "ix = ['a', 'f', 'b', 'd']\n",
    "s2 = Series(d, index = ix)\n",
    "print(s2) # 'e' won't be read in, as it doesn't exist in index. Also 'd' is null since no value exists\n",
    "\n",
    "print(\"\\n**************Adding Series:\")\n",
    "# We can add series together, but if a value doesn't exist in both it's Nan\n",
    "print(s1 + s2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DataFrames\n",
    "A dataframe is a table-like structure comprised of a number of Series of data. This means\n",
    "that the columns can represent different types of data, but each column must be of one type.\n",
    "This makes a dataframe align with CSV's and Relational Databases very easily.\n",
    " - They can be manually generated, imported from CSVs, or loaded from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    state  year  pop\n",
      "0    Ohio  2000  1.5\n",
      "1    Ohio  2001  1.7\n",
      "2    Ohio  2002  3.6\n",
      "3  Nevada  2001  2.4\n",
      "4  Nevada  2002  2.9\n",
      "\n",
      "**************Specifiying column order:\n",
      "   year   state  pop  ext\n",
      "0  2000    Ohio  1.5  NaN\n",
      "1  2001    Ohio  1.7  NaN\n",
      "2  2002    Ohio  3.6  NaN\n",
      "3  2001  Nevada  2.4  NaN\n",
      "4  2002  Nevada  2.9  NaN\n"
     ]
    }
   ],
   "source": [
    "# Dataframes!!\n",
    "\n",
    "# Can construct a dataframe from a dictionary of lists\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "       'year': [2000, 2001, 2002, 2001, 2002],\n",
    "       'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "\n",
    "df = DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n**************Specifiying column order:\")\n",
    "df2 = DataFrame(data, columns = ['year', 'state', 'pop', 'ext']) # This just defines the order of the columns\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Indexing\n",
    "Indexing in DataFrames is very different than indexing with lists, instead it is more comparable to dictionary indexing\n",
    " - We Select by column or index `df['col_name']` or `df['index_val']`\n",
    " - We can select using ints if we use iloc `df.iloc[row, col]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], dtype='object')\n",
      "\n",
      "**************Accessing Colums:\n",
      "Index(['state', 'year', 'pop'], dtype='object')\n",
      "Ohio      2000\n",
      "Ohio      2001\n",
      "Ohio      2002\n",
      "Nevada    2001\n",
      "Nevada    2002\n",
      "Name: year, dtype: int64\n",
      "\n",
      "**************Accessing Rows:\n",
      "Index(['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], dtype='object')\n",
      "     state  year  pop\n",
      "Ohio  Ohio  2000  1.5\n",
      "Ohio  Ohio  2001  1.7\n",
      "Ohio  Ohio  2002  3.6\n",
      "\n",
      "**************Accessing Rows2:\n",
      "state    Nevada\n",
      "year       2001\n",
      "pop         2.4\n",
      "Name: Nevada, dtype: object\n",
      "\n",
      "**************Accessing Rows with Splicing:\n",
      "         state  year  pop\n",
      "Ohio      Ohio  2000  1.5\n",
      "Ohio      Ohio  2002  3.6\n",
      "Nevada  Nevada  2002  2.9\n",
      "\n",
      "**************Accesing columns with Splicing:\n",
      "Ohio      2000\n",
      "Ohio      2001\n",
      "Ohio      2002\n",
      "Nevada    2001\n",
      "Nevada    2002\n",
      "Name: year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dataframes Indexing\n",
    "\n",
    "import pandas as pd #same as numpy, you'll usually see this as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "       'year': [2000, 2001, 2002, 2001, 2002],\n",
    "       'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "\n",
    "\n",
    "df1 = DataFrame(data, index = ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'])\n",
    "print(df1.index)\n",
    "print(\"\\n**************Accessing Colums:\")\n",
    "print(df1.columns) #use df.columns to get a list of column names\n",
    "print(df1['year']) #Like a dictionary we can index into a dataframe's column\n",
    "\n",
    "print(\"\\n**************Accessing Rows:\")\n",
    "print(df1.index) #use df.index to get a list of index names\n",
    "print(df1.loc['Ohio']) #using loc gets you a row based on the index label\n",
    "\n",
    "print(\"\\n**************Accessing Rows2:\")\n",
    "print(df1.iloc[3]) #using loc gets you a row based on the index number\n",
    "\n",
    "print(\"\\n**************Accessing Rows with Splicing:\")\n",
    "print(df1.iloc[::2]) #When using integer based indexing we can use standard python splicing\n",
    "\n",
    "print(\"\\n**************Accesing columns with Splicing:\")\n",
    "print(df1.iloc[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### In class work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "2.05\n",
      "3.25\n",
      "2000\n",
      "1.5\n",
      "2001\n",
      "2.05\n",
      "2002\n",
      "3.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Problem 1\n",
    "\"\"\"Create a subset of the data that only contains records where the population is over 2\"\"\"\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "       'year': [2000, 2001, 2002, 2001, 2002],\n",
    "       'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "df = DataFrame(data)\n",
    "\n",
    "df_sub = df[df['pop']>2]\n",
    "#print(df_sub)\n",
    "\n",
    "\n",
    "#Problem 2\n",
    "\"\"\"Calculate the mean population by year\"\"\"\n",
    "\n",
    "Y_list = df['year'].values\n",
    "\n",
    "Y = set(Y_list)\n",
    "Y = list(Y)\n",
    "\n",
    "Y_dict = dict.fromkeys(Y)\n",
    "#print(Y_dict)\n",
    "\n",
    "for year in df['year'].unique():\n",
    "    mean = np.mean(df[df['year'] == year]['pop'])\n",
    "    print(mean)\n",
    "\n",
    "for i in range(len(df['year'])):\n",
    "    if Y_dict[df['year'][i]]== None:\n",
    "        Y_dict.update({df['year'][i]:[df['pop'][i]]})\n",
    "    else:                                  \n",
    "        Y_dict[df['year'][i]].append(df['pop'][i])\n",
    "\n",
    "\n",
    "for key in Y_dict:\n",
    "    print(key)\n",
    "    print(np.mean(Y_dict[key]))\n",
    "    \n",
    "#df.groupby['year'].mean()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DataFrame Assignment\n",
    "The similarity between DataFrames and dictionaries continues with value assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    state  year  pop\n",
      "0    Ohio  2000    0\n",
      "1    Ohio  2001    0\n",
      "2    Ohio  2002    0\n",
      "3  Nevada  2001    0\n",
      "4  Nevada  2002    0\n",
      "\n",
      "**************Creating Columns:\n",
      "    state  year  pop  sq_miles\n",
      "0    Ohio  2000    0        90\n",
      "1    Ohio  2001    0        63\n",
      "2    Ohio  2002    0        65\n",
      "3  Nevada  2001    0        76\n",
      "4  Nevada  2002    0        67\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "       'year': [2000, 2001, 2002, 2001, 2002],\n",
    "       'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "\n",
    "df1 = DataFrame(data)\n",
    "\n",
    "df1['pop'] = 0 #We can quickly alter entire columns with indexing\n",
    "print(df1)\n",
    "\n",
    "print(\"\\n**************Creating Columns:\")\n",
    "df1['sq_miles'] = np.random.randint(50, 100, size=df1.shape[0]) # We can create a column by indexing at a new col_name\n",
    "# We can also get the dimensions of the df with df.shape() -> (rows, columns)\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Deletions\n",
    "With DataFrames to remove data we need to either **drop** or **delete** it.\n",
    "\n",
    "\n",
    "*Note: a lot of pandas operations have the option to do the operation ***inplace***, otherwise the operation creates a copy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************Deleting Cols:\n",
      "    state  pop\n",
      "0    Ohio  1.5\n",
      "1    Ohio  1.7\n",
      "2    Ohio  3.6\n",
      "3  Nevada  2.4\n",
      "4  Nevada  2.9\n",
      "\n",
      "**************Deleting Rows:\n",
      "         state  year  pop\n",
      "Nevada  Nevada  2001  2.4\n",
      "Nevada  Nevada  2002  2.9\n",
      "\n",
      "**************Deletion By Index:\n",
      "         state  year  pop\n",
      "Nevada  Nevada  2001  2.4\n",
      "Nevada  Nevada  2002  2.9\n"
     ]
    }
   ],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "       'year': [2000, 2001, 2002, 2001, 2002],\n",
    "       'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "\n",
    "print(\"\\n**************Deleting Cols:\")\n",
    "df1 = DataFrame(data)\n",
    "del df1['year'] # Like a dictionary, we can delete a 'key' with the del command\n",
    "print(df1)\n",
    "\n",
    "print(\"\\n**************Deleting Rows:\")\n",
    "df1 = DataFrame(data, index = ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'])\n",
    "df2 = df1.drop('Ohio') # Can also do df1.drop('Ohio', inplace=True) which will update df1\n",
    "print(df2)\n",
    "\n",
    "print(\"\\n**************Deletion By Index:\")\n",
    "df1 = DataFrame(data, index = ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'])\n",
    "df1 = df1[df1.index != 'Ohio'] # Same effect, but no means to do inplace\n",
    "print(df1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Arithmetic\n",
    "Very similar to what we saw when working with Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a   b   c   d\n",
      "0  129  -5 NaN NaN\n",
      "1  118  88 NaN NaN\n",
      "2   90  15 NaN NaN\n",
      "3   87  37 NaN NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Only +, -, *, and / will work with this'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = DataFrame(np.random.randint(-10, 100, size=12).reshape((4, 3)), columns=['a', 'b', 'c'])\n",
    "df2 = DataFrame(np.random.randint(-10, 100, size=12).reshape((4, 3)), columns=['a', 'b', 'd'])\n",
    "\n",
    "print(df1 + df2) #Just like Series arithemetic, non labeled data ends up NaN\n",
    "\"\"\"Only +, -, *, and / will work with this\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Functions - Elementwise\n",
    "There are two ways that we can apply functions to a dataframe, axis or element-wise\n",
    " - Axis based operations act as aggregators and apply a fucnction over columns or rows\n",
    " - Element-wise will update each element based on the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************Original:\n",
      "    a   b   c\n",
      "0 -97  15  60\n",
      "1  20  96  28\n",
      "2 -95 -34 -15\n",
      "3 -25 -90  80\n",
      "\n",
      "**************ABS:\n",
      "    a   b   c\n",
      "0  97  15  60\n",
      "1  20  96  28\n",
      "2  95  34  15\n",
      "3  25  90  80\n",
      "\n",
      "**************Square:\n",
      "      a     b     c\n",
      "0  9409   225  3600\n",
      "1   400  9216   784\n",
      "2  9025  1156   225\n",
      "3   625  8100  6400\n"
     ]
    }
   ],
   "source": [
    "# Element based function applications\n",
    "\n",
    "df1 = DataFrame(np.random.randint(-100, 100, size=12).reshape((4, 3)), columns=['a', 'b', 'c'])\n",
    "df2 = DataFrame(np.random.randint(-100, 100, size=12).reshape((4, 3)), columns=['a', 'b', 'd'])\n",
    "\n",
    "print(\"\\n**************Original:\")\n",
    "print(df1)\n",
    "\n",
    "print(\"\\n**************ABS:\")\n",
    "print(np.abs(df1)) # We can use any of the numpy ufuncs\n",
    "\n",
    "print(\"\\n**************Square:\")\n",
    "print(np.square(df1)) # We can use any of the numpy ufuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames Functions - Axis (apply)\n",
    " - With DataFrames we can apply functions across the dataframes *axis*.\n",
    "  - axis=0 -> cols\n",
    "  - axis=1 -> rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = DataFrame(np.random.randint(-100, 100, size=12).reshape((4, 3)), columns=['a', 'b', 'c'])\n",
    "df2 = DataFrame(np.random.randint(-100, 100, size=12).reshape((4, 3)), columns=['a', 'b', 'd'])\n",
    "\n",
    "\"\"\"There are two ways that we can apply functions to a dataframe, axis or element-wise\n",
    "    - Axis based operations act as aggregators and apply a fucnction over columns or rows\n",
    "    - Element-wise will update each element based on the function\"\"\"\n",
    "\n",
    "print(\"\\n**************Original:\")\n",
    "print(df1)\n",
    "\n",
    "# Axis based function applications\n",
    "\n",
    "print(\"\\n**************Applying Functions, by Col:\")\n",
    "func = lambda x: x.max() - x.min()\n",
    "print(df1.apply(func))\n",
    "\n",
    "print(\"\\n**************Applying Functions, by Row:\")\n",
    "func = lambda x: x.max() - x.min()\n",
    "print(df1.apply(func, axis=1))\n",
    "\n",
    "\n",
    "# We can also change the type of object formed by changing the output of our func\n",
    "print(\"\\n**************Generating aggregate data:\")\n",
    "func = lambda x: Series([x.min(), x.max()], index=['min', 'max'])\n",
    "\n",
    "\"\"\"This works because we remove one dimension of the data with the apply() method,\n",
    "and then create a new dimension from the return value\"\"\"\n",
    "\n",
    "print(df1.apply(func))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### In class work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    state  year  Nominal GDP  GDP Deflator    Real GDP\n",
      "0    Ohio  2000        395.1         82.59  478.387214\n",
      "1    Ohio  2001        398.9         84.23  473.584234\n",
      "2    Ohio  2002        414.2         85.65  483.596030\n",
      "3  Nevada  2001        102.2         84.23  121.334441\n",
      "4  Nevada  2002        105.4         85.65  123.058961\n"
     ]
    }
   ],
   "source": [
    "#Problem 1\n",
    "\"\"\"Given (GDP Deflator = [Nominal GDP/Real GDP] * 100) calculate the real GDP per row\n",
    "using pandas apply() method and append the results to the current dataframe\"\"\"\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "       'year': [2000, 2001, 2002, 2001, 2002],\n",
    "       'Nominal GDP': [395.1, 398.9, 414.2, 102.2, 105.4],\n",
    "       'GDP Deflator': [82.59, 84.23, 85.65, 84.23, 85.65]}\n",
    "df = DataFrame(data)\n",
    "\n",
    "func = lambda x: x\n",
    "['Nominal GDP'] *100 / x['GDP Deflator']\n",
    "df['Real GDP']= df.apply(func, axis = 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sorting DataFrames\n",
    "Sorting a DataFames can be done by index or by column. The index sorting or `df.sort_index()` enables us to sort columns or rows by their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(np.arange(8).reshape((2,4)), index=['three', 'one'],\n",
    "              columns=['d', 'a', 'b', 'c'])\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# This will sort the indexes of the dataframe\n",
    "df.sort_index(inplace=True) # Inplace is necessary to update the df object, otherwise need to store output in var\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# This will sort the columns of the dataframe\n",
    "df.sort_index(inplace=True, axis=1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by the values of a DataFrame means to `df.sort_values(by=cols)`. This will sort the dataframe by the columns, in order. So `df.sort_values(by=[col1, col2])` would sort by col1 first, and then deal with any duplicate values in col1 by sorting on the values in col2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting Continued\n",
    "\n",
    "df = DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "df.sort_values(by=['a', 'b'], inplace=True, ascending=False)\n",
    "print(df) #We should see that the df is sorted by a first, and then b\n",
    "print()\n",
    "\n",
    "df.sort_values(by=['b', 'a'], inplace=True, ascending=False)\n",
    "print(df)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Stats\n",
    "Pandas also enables us to generate stats very easily (from the typical stats functionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas statistics\n",
    "\n",
    "\"\"\"Some methods that exist:\n",
    "    - count\n",
    "    - min, max\n",
    "    - sum\n",
    "    - mean\n",
    "    - median\n",
    "    - mad (mean absolute deviation from mean value)\n",
    "    - var\n",
    "    - std\n",
    "    - skew (skewness of the data 3rd movement) - (1st is mean, 2nd is var, 3rd skew, 4th is kurtosis)\n",
    "    - kurt (kurtosis 4th movement)\n",
    "\"\"\"\n",
    "\n",
    "df = DataFrame(np.random.randint(-100, 100, size=20).reshape((5, 4)), columns=['a', 'b', 'c', 'd'])\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "print(df.describe()) # The describe() method gives a good summary of each series in the df\n",
    "print()\n",
    "\n",
    "# But we can also get specific stats, by calling their methods\n",
    "print(df.sum())\n",
    "print()\n",
    "print(df.sum(axis=1)) # And with most methods, we can change the axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### In class work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1\n",
    "\"\"\"Given the following dataframe (df) determine which rows have values, for every column,\n",
    "that fall outside (mean - 1std) for the given column\n",
    "E.G. For row x values in colummns a, b, c, and d are further than 1 std away from the mean for column a, b, c, and d\n",
    "\n",
    "Should find rows 24 and 28\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(12)\n",
    "df = DataFrame(np.random.randint(-100, 100, size=200).reshape((50, 4)), columns=['a', 'b', 'c', 'd'])\n",
    "\n",
    "out_df = df.copy()\n",
    "\n",
    "for col in df.columns:\n",
    "    out_df[col] = np.abs(out_df[col] - out_df[col].mean()) > np.abs(out_df[col].mean() - out_df[col].std())\n",
    "\n",
    "print(out_df[out_df.apply(sum, axis=1) == 4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pandas Correlation and Covariance\n",
    "This isn't as practical as numpy because it won't be uncommon to have non-numeric data in our dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation and Covariance\n",
    "\n",
    "a = np.arange(10)\n",
    "b = np.arange(0, 20, 2)\n",
    "c = np.arange(10)\n",
    "c.sort()\n",
    "c = c[::-1]\n",
    "d = np.random.randint(-10, 10, size=10)\n",
    "\n",
    "df = DataFrame({'a': a, 'b': b, 'c': c, 'd': d})\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "print(df.cov())\n",
    "print()\n",
    "\n",
    "print(df.corr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Uniques\n",
    "We can find unique values by simply calling `df[col].unique()`. This is because only Series have a unique method.\n",
    "\n",
    "Similarly we can call `df[col].value_counts()` to determine how frequent each value in a Series is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uniques\n",
    "\n",
    "df = DataFrame(np.random.randint(-10, 10, size=100).reshape((25, 4)), columns=['a', 'b', 'c', 'd'])\n",
    "print(df['a'].unique()) #Unique method only exists for Series data, not DataFrames\n",
    "print()\n",
    "\n",
    "print(df['a'].value_counts().sort_index()) #value_counts gives us a count of values in a Series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isin()\n",
    "Just like python's x in y functionality, we can do the same thing usuing `df[col].isin(lst)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isin() method\n",
    "\n",
    "df = DataFrame(np.random.randint(-10, 10, size=100).reshape((25, 4)), columns=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# isin() helps us identify indexes where values of interest lie\n",
    "# It generates a true/false vector for use with subsetting\n",
    "for ix in range(-10, 10):\n",
    "    val_in = df['a'].isin([ix])\n",
    "    print(\"Rows with {} in:\\n{}\\n\".format(ix, df['a'][val_in]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
